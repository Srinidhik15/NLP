{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48a324c",
   "metadata": {},
   "source": [
    "# Types of Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190957aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eating',\n",
       " 'eats',\n",
       " 'eaten',\n",
       " 'writing',\n",
       " 'writes',\n",
       " 'programming',\n",
       " 'programs',\n",
       " 'history',\n",
       " 'finally',\n",
       " 'finalized']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c3f62",
   "metadata": {},
   "source": [
    "#### 1. PorterStemmer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94287f70",
   "metadata": {},
   "source": [
    "# It is based on the idea that the suffixes in the English language are made up of a combination of smaller and simpler suffixes. This stemmer is known for its speed and simplicity. The main applications of Porter Stemmer include data mining and Information retrieval. However, its applications are only limited to English words. Also, the group of stems is mapped on to the same stem and the output stem is not necessarily a meaningful word. The algorithms are fairly lengthy in nature and are known to be the oldest stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cb81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acbb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c52f9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "porterstemp = [stemming.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8cc7564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original words: ['eating', 'eats', 'eaten', 'writing', 'writes', 'programming', 'programs', 'history', 'finally', 'finalized']\n",
      "stemmed words: ['eat', 'eat', 'eaten', 'write', 'write', 'program', 'program', 'histori', 'final', 'final']\n"
     ]
    }
   ],
   "source": [
    "print(\"original words:\", words)\n",
    "print(\"stemmed words:\", porterstemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e6101",
   "metadata": {},
   "source": [
    "#### 2. Snowball Stemmer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cc5e673",
   "metadata": {},
   "source": [
    "# The Snowball Stemmer, compared to the Porter Stemmer, is multi-lingual as it can handle non-English words. It supports various languages and is based on the ‘Snowball’ programming language, known for efficient processing of small strings.. The Snowball stemmer is way more aggressive than Porter Stemmer and is also referred to as Porter2 Stemmer. Because of the improvements added when compared to the Porter Stemmer, the Snowball stemmer is having greater computational speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2076c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9e5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ea2b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original words: ['eating', 'eats', 'eaten', 'writing', 'writes', 'programming', 'programs', 'history', 'finally', 'finalized']\n",
      "stemmed words: ['eat', 'eat', 'eaten', 'write', 'write', 'program', 'program', 'histori', 'final', 'final']\n"
     ]
    }
   ],
   "source": [
    "print(\"original words:\", words)\n",
    "print(\"stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfbb3e",
   "metadata": {},
   "source": [
    "#### 3.Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7f10742",
   "metadata": {},
   "source": [
    "# The Lancaster stemmers are more aggressive and dynamic compared to the other two stemmers. The stemmer is really faster, but the algorithm is really confusing when dealing with small words. But they are not as efficient as Snowball Stemmers. The Lancaster stemmers save the rules externally and basically uses an iterative algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18698427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0581e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4b780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original words: ['eating', 'eats', 'eaten', 'writing', 'writes', 'programming', 'programs', 'history', 'finally', 'finalized']\n",
      "stemmed words: ['eat', 'eat', 'eat', 'writ', 'writ', 'program', 'program', 'hist', 'fin', 'fin']\n"
     ]
    }
   ],
   "source": [
    "print(\"original words:\", words)\n",
    "print(\"stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf477d2",
   "metadata": {},
   "source": [
    "#### 4. Regexp Stemmer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d56d1dba",
   "metadata": {},
   "source": [
    "# The Regexp Stemmer, or Regular Expression Stemmer, is a stemming algorithm that utilizes regular expressions to identify and remove suffixes from words. It allows users to define custom rules for stemming by specifying patterns to match and remove.. This method provides flexibility and control over the stemming process, making it suitable for specific applications where custom rule-based stemming is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d424668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e988fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "371c609b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_word = reg_stemmer.stem('eating')\n",
    "stemmed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a82e0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d235f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39fd2b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli', 'goe')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# porter stem\n",
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\"), stemming.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1196970d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport', 'goe')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# snowball stem\n",
    "stemmer.stem(\"fairly\"),stemmer.stem(\"sportingly\"), stemmer.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77e99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
